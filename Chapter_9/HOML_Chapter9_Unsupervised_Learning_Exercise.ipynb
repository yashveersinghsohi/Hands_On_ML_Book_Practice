{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6lMegOmj+Q9KzMVY+Mhvx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashveersinghsohi/Hands_On_ML_Book_Practice/blob/master/Chapter_9/HOML_Chapter9_Unsupervised_Learning_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "txbtTDHyeiFY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aMeNr4g9ee-c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "\n",
        "# from sklearn.metrics import silhouette_score, silhouette_samples\n",
        "# from sklearn.datasets import load_iris\n",
        "# from sklearn.datasets import make_blobs\n",
        "# from sklearn.cluster import KMeans\n",
        "# from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
        "# from yellowbrick.cluster import SilhouetteVisualizer\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "GyS3Gz7ocq-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "olivetti = fetch_olivetti_faces()"
      ],
      "metadata": {
        "id": "Dza7UbKIeoZP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(olivetti.DESCR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-yQKBQhcudw",
        "outputId": "f212d79f-6d04-49c2-94fb-a43caa33aed4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _olivetti_faces_dataset:\n",
            "\n",
            "The Olivetti faces dataset\n",
            "--------------------------\n",
            "\n",
            "`This dataset contains a set of face images`_ taken between April 1992 and \n",
            "April 1994 at AT&T Laboratories Cambridge. The\n",
            ":func:`sklearn.datasets.fetch_olivetti_faces` function is the data\n",
            "fetching / caching function that downloads the data\n",
            "archive from AT&T.\n",
            "\n",
            ".. _This dataset contains a set of face images: https://cam-orl.co.uk/facedatabase.html\n",
            "\n",
            "As described on the original website:\n",
            "\n",
            "    There are ten different images of each of 40 distinct subjects. For some\n",
            "    subjects, the images were taken at different times, varying the lighting,\n",
            "    facial expressions (open / closed eyes, smiling / not smiling) and facial\n",
            "    details (glasses / no glasses). All the images were taken against a dark\n",
            "    homogeneous background with the subjects in an upright, frontal position \n",
            "    (with tolerance for some side movement).\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    =================   =====================\n",
            "    Classes                                40\n",
            "    Samples total                         400\n",
            "    Dimensionality                       4096\n",
            "    Features            real, between 0 and 1\n",
            "    =================   =====================\n",
            "\n",
            "The image is quantized to 256 grey levels and stored as unsigned 8-bit \n",
            "integers; the loader will convert these to floating point values on the \n",
            "interval [0, 1], which are easier to work with for many algorithms.\n",
            "\n",
            "The \"target\" for this database is an integer from 0 to 39 indicating the\n",
            "identity of the person pictured; however, with only 10 examples per class, this\n",
            "relatively small dataset is more interesting from an unsupervised or\n",
            "semi-supervised perspective.\n",
            "\n",
            "The original dataset consisted of 92 x 112, while the version available here\n",
            "consists of 64x64 images.\n",
            "\n",
            "When using these images, please give credit to AT&T Laboratories Cambridge.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c-hEFCCnczjo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}